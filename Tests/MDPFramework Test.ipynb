{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataclasses import *\n",
    "from typing import *\n",
    "import scipy.integrate as integrate\n",
    "import unittest \n",
    "import timeit\n",
    "import random\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/niyi/Documents/GitHub/Optimal-Control/Tools')\n",
    "from EnforceTyping import enforce_method_typing, EnforceClassTyping\n",
    "from MDPFramework import MDPEnvironment, MDPController, LearningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(unsafe_hash=True, order=True)\n",
    "class Node(EnforceClassTyping):\n",
    "  id: Union[str, int, float, np.ndarray]\n",
    "  neighbors: Dict\n",
    "  def __repr__(self) -> str:\n",
    "    neighbor_ids= tuple(neighbor.id for neighbor in self.neighbors['Nodes'])\n",
    "    name= str(self.id)+ ':'+ str(neighbor_ids)\n",
    "    return name\n",
    "  \n",
    "  def add_neighbor(self, neighbor: 'Node', distance: int):\n",
    "    \"\"\"\n",
    "    Adds a neighbor to the node's list of neighbors.\n",
    "    \"\"\"\n",
    "    self.neighbors['Nodes'].append(neighbor) \n",
    "    self.neighbors['Distance'].append(distance) \n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Graph(EnforceClassTyping):\n",
    "  n_vertices: int\n",
    "  n_egdes: int\n",
    "  network: Tuple[Node]= ()\n",
    "\n",
    "  def transition_probability(self, node: Node):\n",
    "    return np.array(node.neighbors['Distance'])/sum(node.neighbors['Distance'])\n",
    "  \n",
    "  def __post_init__(self):\n",
    "    nodes= self.generate_states_space(self.n_vertices)\n",
    "    self.network= self.randomly_connect_state_space(nodes, self.n_egdes)\n",
    "  \n",
    "  def add_node(self, node: Node):\n",
    "    \"\"\"\n",
    "    Adds a new node to the network.\n",
    "    \"\"\"\n",
    "    self.network= self.network+ (node, )\n",
    "\n",
    "  def generate_states_space(self, n_nodes: int)-> Tuple[Node]:\n",
    "    nodes= ()\n",
    "    for i in range(n_nodes):\n",
    "      nodes= nodes+ (Node(id= i, neighbors={\"Nodes\": [ ],\n",
    "                                            \"Distance\": [ ]}), )\n",
    "    return nodes\n",
    "\n",
    "  def randomly_connect_state_space(self, nodes: Tuple[Node], n_connections: int)-> Tuple[Node]:\n",
    "    for _ in range(n_connections):\n",
    "      random_state1, random_state2= random.sample(sorted(nodes), 2)\n",
    "      if not self.are_connected(random_state1, random_state2):\n",
    "          self.connect_nodes(random_state1, random_state2, np.random.randint(1, 100))\n",
    "    return nodes\n",
    "\n",
    "  def connect_nodes(self, node1: Node, node2: Node, distance: int):\n",
    "    \"\"\"\n",
    "    Connects two nodes in the network by adding each other to their respective neighbor lists.\n",
    "    \"\"\"\n",
    "    node1.add_neighbor(node2, distance)\n",
    "    node2.add_neighbor(node1, distance)\n",
    "\n",
    "  def are_connected(self, node1: Node, node2: Node):\n",
    "     are_connected= node1 in node2.neighbors[\"Nodes\"] and node2 in node1.neighbors[\"Nodes\"]\n",
    "     return are_connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(kw_only=True)\n",
    "class MarkovChain(MDPEnvironment):\n",
    "  \n",
    "  @dataclass(unsafe_hash=True, order=True)\n",
    "  class State(Node):\n",
    "    pass\n",
    "  \n",
    "  state_space: Graph\n",
    "  terminal_signal_weight: float= 100\n",
    "  initial_state: State= None\n",
    "  current_state: State= None\n",
    "\n",
    "  def __post_init__(self):\n",
    "    self.initial_state= random.choice(self.state_space.network)\n",
    "    self.current_state= self.initial_state\n",
    "\n",
    "  def state_transition_model(self, state: State, action: np.ndarray=None)-> State:\n",
    "    transition_probabilities= self.state_space.transition_probability(state)\n",
    "    next_state= random.choices(state.neighbors['Nodes'], weights= transition_probabilities)[0]\n",
    "    return next_state\n",
    "    \n",
    "  def reward_model(self, state: State, next_state: State, terminal_signal: bool, action: np.ndarray= None)-> float:\n",
    "    '''This is a scalar performance metric.'''\n",
    "    next_state_index= state.neighbors['Nodes'].index(next_state)\n",
    "    distance_gained = state.neighbors['Distance'][next_state_index]\n",
    "    reward = (distance_gained + self.terminal_signal_weight * int(terminal_signal))\n",
    "    return reward\n",
    "\n",
    "  def is_terminal_condition(self, state: State)-> bool:\n",
    "    if len(state.neighbors['Nodes']) < 2:\n",
    "      return True\n",
    "    else:\n",
    "       return False\n",
    "\n",
    "  def transition_step(self, state: State, action: np.ndarray = None) -> Tuple[State, float, bool]:\n",
    "      \"\"\"\n",
    "      Simulates a single time step of the environment.\n",
    "\n",
    "      Args:\n",
    "          state (State): The current state of the environment. Defaults to current_state.\n",
    "          action (np.ndarray): The action to take in the environment. Defaults to [0.0, 0.0].\n",
    "          time_interval (float): The time interval for the simulation. Defaults to 0.1.\n",
    "\n",
    "      Returns:\n",
    "          Tuple[State, float, bool]: A tuple containing the next state, the reward, and a terminal signal.\n",
    "      \"\"\"\n",
    "      next_state = self.state_transition_model(state)\n",
    "      terminal_signal = self.is_terminal_condition(next_state)\n",
    "      reward = self.reward_model(state, next_state, terminal_signal)\n",
    "      return next_state, reward, terminal_signal\n",
    "\n",
    "  def sample_trajectory(self, n_steps: int, initial_state: State = None) -> Tuple[List[State], float, List[float]]:\n",
    "      \"\"\"\n",
    "      Generates a random state trajectory within the viable learning region.\n",
    "\n",
    "      Args:\n",
    "      - runtime (float): The total time for the trajectory in seconds.\n",
    "      - initial_state (State): The initial state of the trajectory. Defaults to current_state.\n",
    "      - n_steps (int): The number of steps in the trajectory. Defaults to 200.\n",
    "\n",
    "      Returns:\n",
    "      - A tuple containing the state trajectory, action trajectory, and time points.\n",
    "      \"\"\"\n",
    "      if initial_state == None:\n",
    "         state = self.current_state\n",
    "      else:\n",
    "         state = initial_state\n",
    "      state_trajectory = []\n",
    "      time_span = range(n_steps)\n",
    "      return_value= 0.0\n",
    "\n",
    "      for t in time_span:\n",
    "          state_trajectory.append(state)\n",
    "          state, reward, _ = self.transition_step(state)\n",
    "          return_value += reward\n",
    "      return state_trajectory, return_value, time_span\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Unit tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:(2, 1)\n",
      "[0.35869565 0.64130435]\n",
      "[8:(4, 6, 7), 7:(5, 1, 3, 8), 3:(9, 6, 7, 2), 7:(5, 1, 3, 8), 8:(4, 6, 7), 6:(2, 5, 3, 8), 8:(4, 6, 7), 6:(2, 5, 3, 8), 3:(9, 6, 7, 2), 7:(5, 1, 3, 8), 5:(9, 6, 7), 7:(5, 1, 3, 8), 5:(9, 6, 7), 7:(5, 1, 3, 8), 3:(9, 6, 7, 2), 9:(5, 3, 4), 5:(9, 6, 7), 9:(5, 3, 4), 4:(9, 8, 2), 2:(0, 6, 4, 3)]\n"
     ]
    }
   ],
   "source": [
    "test_graph= Graph(n_vertices=10, n_egdes=20)\n",
    "\n",
    "test_markov_chain= MarkovChain(state_space=test_graph)\n",
    "node= test_markov_chain.state_space.network[0]\n",
    "print(test_graph.network[0])\n",
    "print(test_graph.transition_probability(node))\n",
    "test_trace, test_return, time_span= test_markov_chain.sample_trajectory(20)\n",
    "print(test_trace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Integration tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Functional tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Performance tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
