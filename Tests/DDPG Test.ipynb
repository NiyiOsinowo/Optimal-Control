{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataclasses import *\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os\n",
    "project_path= os.path.dirname(os.path.abspath(os.curdir))\n",
    "import sys\n",
    "sys.path.insert(0, project_path+ '/Tools')\n",
    "sys.path.insert(1, project_path+ '/Optimal Control Methods/Learning Methods/Model Free RL')\n",
    "sys.path.insert(2, project_path+ '/Systems')\n",
    "from EnforceTyping import enforce_method_typing\n",
    "from ParticlesandFields import Field, ClassicalParticle, ParticleInField\n",
    "from DDPG import DDPGAgent, DDPGAlgorithm\n",
    "T.Tensor.ndim = property(lambda self: len(self.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "coulomb_constant = 8.9875e9  # N*m^2/C^2\n",
    "@dataclass(kw_only=True)\n",
    "class ElectrostaticField2D(Field):\n",
    "  \"\"\"\n",
    "  A class used to represent a 2D Electrostatic Field\n",
    "\n",
    "  Attributes\n",
    "  ----------\n",
    "  field_sources: dict\n",
    "      a formatted string to print out what the animal says\n",
    "  dimensionality: tuple\n",
    "      a tuple of the dimensionality of the field  \n",
    "\n",
    "  Methods\n",
    "  -------\n",
    "  dynamics(self, observation_position: np.ndarray, time: float) -> np.ndarray:\n",
    "      Represents the value of the field at any given point(s) or time. \n",
    "  potential(self, observation_position: np.ndarray, time: float) -> float:\n",
    "      Represents the potential due to the field at a given position and/or time  \n",
    "  potential_difference(self, initial_position: np.ndarray, final_position: np.ndarray, time: float) -> float:\n",
    "      Represents the potential difference between two positions at a given time in the vector field   \n",
    "  gradient(self, observation_position: np.ndarray, time: float) -> float:\n",
    "      Represents the gradient at a given position and/or time in the vector field \n",
    "  curl(self, observation_position: np.ndarray, time: float) -> float:\n",
    "      Represents the curl at a given position and/or time in the vector field \n",
    "  divergence(self, observation_position: np.ndarray, time: float) -> float:\n",
    "      Represents the divergence at a given position and/or time in the vector field\n",
    "  \"\"\"\n",
    "  field_sources: dict\n",
    "  dimensionality: tuple = (2,)\n",
    "\n",
    "  def __call__(self, observation_position: np.ndarray) -> np.ndarray:\n",
    "      return self.dynamics(observation_position)\n",
    "\n",
    "  def __post_init__(self):\n",
    "    assert len(self.field_sources[\"Particle\"]) == len(self.field_sources[\"Position\"]), \"The length of particles and fields don't match\"\n",
    "    for field_source, _ in zip(self.field_sources[\"Particle\"], self.field_sources[\"Position\"]):\n",
    "        assert isinstance(field_source, ClassicalParticle),  \"The field source is not a particle\" \n",
    "\n",
    "  @enforce_method_typing\n",
    "  def dynamics(self, observation_position: np.ndarray) -> np.ndarray:\n",
    "      \"\"\"\n",
    "      This function outputs the field strength due to field sources experienced at any given point(s) or time. \n",
    "      This determines the physics of the field (a 2D Electricstatic Field in this case)\n",
    "\n",
    "      Args:\n",
    "          observation_position (np.ndarray): The position.\n",
    "\n",
    "      Returns:\n",
    "          np.ndarray: The electric field strength vector at the given position.\n",
    "      \"\"\"\n",
    "      electric_field_vector = np.zeros_like(observation_position)\n",
    "      for field_source, source_position in zip(self.field_sources[\"Particle\"], self.field_sources[\"Position\"]):\n",
    "          position_vectors = np.broadcast_to(source_position, reversed(observation_position.shape)).T\n",
    "          displacement_vectors = observation_position - position_vectors\n",
    "          displacement_magnitude = np.linalg.norm(displacement_vectors, axis=0)\n",
    "          electric_field_vector += (displacement_vectors * field_source.charge) / displacement_magnitude**3\n",
    "      electric_field_vector = coulomb_constant * electric_field_vector\n",
    "      return np.round(electric_field_vector, 3)  # N/C or V/m\n",
    "\n",
    "  @enforce_method_typing\n",
    "  def potential(self, observation_position: np.ndarray) -> float:\n",
    "      \"\"\"\n",
    "      Calculate the potential (voltage) at a position in the field.\n",
    "\n",
    "      Args:\n",
    "          observation_position (np.ndarray): The position.\n",
    "\n",
    "      Returns:\n",
    "          np.ndarray: The electric potential at the given position.\n",
    "      \"\"\"\n",
    "      electric_potential = 0.0\n",
    "      for field_source, source_position in zip(self.field_sources[\"Particle\"], self.field_sources[\"Position\"]):\n",
    "          position_vectors = np.broadcast_to(source_position, reversed(observation_position.shape)).T\n",
    "          displacement_vectors = observation_position - position_vectors\n",
    "          displacement_magnitude = np.linalg.norm(displacement_vectors, axis=0)\n",
    "          electric_potential += field_source.charge / displacement_magnitude\n",
    "      electric_potential = coulomb_constant * electric_potential\n",
    "      return np.round(electric_potential, 3)  # V\n",
    "\n",
    "  @enforce_method_typing\n",
    "  def potential_difference(self, initial_position: np.ndarray, final_position: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the potential difference between the initial position and the final position in the field.\n",
    "\n",
    "    Args:\n",
    "        initial_position (np.ndarray): The starting position.\n",
    "        final_position (np.ndarray): The ending position.\n",
    "        resolution (int, optional): The number of intervals to divide the path into. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        float: The work required to move from the initial position to the final position.\n",
    "    \"\"\"\n",
    "    assert initial_position.shape == self.dimensionality, \"initial_position has the wrong dimensions\"\n",
    "    assert final_position.shape == self.dimensionality, \"final_position has the wrong dimensions\"\n",
    "    PorentialDifference= self.potential(initial_position)- self.potential(final_position)\n",
    "    return PorentialDifference\n",
    "\n",
    "  @enforce_method_typing\n",
    "  def gradient(self, observation_position: np.ndarray, delta: float= 0.001)->np.ndarray:\n",
    "    \"\"\"\n",
    "    This function returns the derivative of the field at a given point\n",
    "\n",
    "    Args:\n",
    "        observation_position (np.ndarray): The position.\n",
    "        delta (float, optional): The step size. Defaults to 0.001.\n",
    "\n",
    "    Returns: \n",
    "      np.ndarray: The gradient of the field at the given position.\n",
    "    \"\"\"\n",
    "    gradient= np.zeros_like(observation_position)\n",
    "    for i in range(len(observation_position)):\n",
    "      di= np.zeros_like(observation_position)\n",
    "      di[i, ] = di[i, ]+delta\n",
    "      plusdi= observation_position+ di\n",
    "      minusdi= observation_position- di\n",
    "      gradient[i]= (self.dynamics(plusdi)- self.dynamics(minusdi))[i]/ (2* delta)\n",
    "    return gradient\n",
    "\n",
    "  @enforce_method_typing\n",
    "  def plot_field(self, low_bound= -5, high_bound= 5, n_vectors= 50):\n",
    "    \"\"\"\n",
    "    This function plots the 2D electric vector field\n",
    "\n",
    "    Args:\n",
    "    low_bound (float, optional): The lower bound of the plot. Defaults to -5.\n",
    "    high_bound (float, optional): The upper bound of the plot. Defaults to 5.\n",
    "    n_vectors (int, optional): The number of vectors to plot. Defaults to 50.\n",
    "\n",
    "    \"\"\"\n",
    "    observation_position= np.meshgrid(np.linspace(low_bound, high_bound, n_vectors), \n",
    "                                    np.linspace(low_bound, high_bound, n_vectors))\n",
    "    observation_position= np.stack(observation_position)\n",
    "    xd, yd = self.dynamics(observation_position)\n",
    "    xd = xd / np.sqrt(xd**2 + yd**2)\n",
    "    yd = yd / np.sqrt(xd**2 + yd**2)\n",
    "    color_aara = np.sqrt(xd**2+ yd**2)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    cp = ax.quiver(observation_position[0],observation_position[1],xd,yd,color_aara)\n",
    "    fig.colorbar(cp)\n",
    "    plt.rcParams['figure.dpi'] = 150\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_charge= ClassicalParticle(mass=1e-14, charge= -1e-9)\n",
    "positive_charge= ClassicalParticle(mass=1e-14, charge= 1e-9)\n",
    "sources = {\"Particle\": [negative_charge, positive_charge],\n",
    "           \"Position\": [np.array([1.0, 1.0]), np.array([-1.0, 1.0])]} \n",
    "target= np.array([0.0, 0.0])\n",
    "test_electric_field= ElectrostaticField2D(field_sources=sources)\n",
    "point_charge_in_electric_field= ParticleInField(field=test_electric_field, \n",
    "                                               particle=positive_charge, \n",
    "                                               target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actor_layer= (10, 5)\n",
    "test_critic_layer= (10, 5)\n",
    "test_actor_activations= (nn.ReLU(), nn.ReLU())\n",
    "test_critic_activations= (nn.ReLU(), nn.ReLU())\n",
    "test_agent = DDPGAgent(point_charge_in_electric_field,\n",
    "                       actor_layers=test_actor_layer, \n",
    "                       critic_layers=test_critic_layer,\n",
    "                       actor_activations= test_actor_activations,\n",
    "                       critic_activations= test_critic_activations,\n",
    "                       observation_size= 4,\n",
    "                       action_size= 2,\n",
    "                       actor_learning_rate= 0.01,\n",
    "                       critic_learning_rate= 0.01,\n",
    "                       soft_update_rate=0.01,\n",
    "                       max_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.5877, -1.3812,  0.0000,  0.0000])\n",
      "tensor([ 1.5245e-12, -2.4199e-12])\n",
      "tensor([-0.1735], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_state= test_agent.observe()\n",
    "test_action= test_agent.act(test_state)\n",
    "test_value= test_agent.critic.forward(test_state, test_action)\n",
    "# print(test_agent.policy)\n",
    "print(test_state)\n",
    "print(test_action)\n",
    "print(test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([], maxlen=5)\n",
      "(tensor([ 6.9323, -3.5784,  0.0000,  0.0000]), tensor([ 4.5543e-12, -1.0386e-11]), tensor([  6.6715,  -3.2797, -41.1543,  46.9327]), -999.6326961548343, True)\n",
      "(tensor([-7.0105,  0.2341,  0.0000,  0.0000]), tensor([ 1.3862e-12, -3.0780e-12]), tensor([ -7.3122,   0.1725, -76.3536, -15.6811]), -1000.2998342113375, True)\n",
      "(tensor([-0.4592, -6.3109,  0.0000,  0.0000]), tensor([-2.1014e-12, -1.2682e-12]), tensor([ 2.9044e-02, -6.4039e+00,  6.3720e+01, -9.9566e+00]), -1000.0762913161367, True)\n",
      "(tensor([-5.2405,  4.0761,  0.0000,  0.0000]), tensor([ 1.2647e-12, -6.5858e-12]), tensor([ -5.3424,   4.1850, -43.5753,  46.6759]), -1000.1473158503155, True)\n",
      "(tensor([-0.8473,  8.4306,  0.0000,  0.0000]), tensor([ 5.1967e-13, -1.1839e-11]), tensor([-4.4974e-01,  8.4410e+00,  5.7563e+01, -1.0365e-02]), -999.9799278894652, True)\n",
      "(tensor([-1.9693,  7.6907,  0.0000,  0.0000]), tensor([ 2.9328e-13, -1.2194e-11]), tensor([-1.5286,  7.9844, 60.2255, 36.9342]), -1000.1906050446163, True)\n",
      "(tensor([8.9074, 1.1744, 0.0000, 0.0000]), tensor([ 5.2140e-12, -1.1478e-11]), tensor([  8.3524,   1.0271, -76.2239, -19.1314]), -999.4308059096732, True)\n",
      "(tensor([1.2166, 4.1041, 0.0000, 0.0000]), tensor([ 4.8089e-12, -1.3512e-11]), tensor([  1.2413,   4.0677,  38.4371, -57.0780]), -999.9722176589262, True)\n"
     ]
    }
   ],
   "source": [
    "print(test_agent.memory)\n",
    "for _ in range(8):\n",
    "    rand_state= point_charge_in_electric_field.random_state()\n",
    "    rand_observation= test_agent.observe(rand_state)\n",
    "    rand_action= test_agent.act(rand_observation)\n",
    "    rand_next_state, rand_reward, rand_terminal_signal= point_charge_in_electric_field.transition_step(rand_state, np.array(rand_action), test_agent.control_interval) \n",
    "    test_agent.memory.append((rand_observation, rand_action, test_agent.observe(rand_next_state), rand_reward, rand_terminal_signal))\n",
    "    print(test_agent.memory[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = random.sample(test_agent.memory, test_agent.batch_size)\n",
    "observations, actions, next_observations, rewards, dones = zip(*batch)\n",
    "\n",
    "state = T.stack(observations).to(test_agent.critic.device)\n",
    "action = T.stack(actions).to(test_agent.critic.device)\n",
    "reward = T.tensor(rewards, dtype=T.float).unsqueeze(1).to(test_agent.critic.device)\n",
    "new_state = T.stack(next_observations).to(test_agent.critic.device)\n",
    "done = T.tensor(dones, dtype=T.float).unsqueeze(1).to(test_agent.critic.device)\n",
    "\n",
    "test_agent.target_actor.eval()\n",
    "test_agent.target_critic.eval()\n",
    "test_agent.critic.eval()\n",
    "\n",
    "target_actions = self.actor.forward(new_state)\n",
    "critic_value_ = self.target_critic.forward(new_state, target_actions) \n",
    "q_expected = self.critic.forward(state, action)\n",
    "q_targets = reward + self.discount_rate * critic_value_ * (1 - done)\n",
    "\n",
    "critic_loss = nn.MSELoss()(q_expected, q_targets.detach())\n",
    "self.critic.train()\n",
    "self.critic.optimizer.zero_grad()\n",
    "critic_loss.backward()\n",
    "self.critic.optimizer.step()\n",
    "\n",
    "self.actor.eval()\n",
    "self.critic.eval()\n",
    "\n",
    "mu = self.actor.forward(state)\n",
    "Actor_loss = -self.critic.forward(state, mu)\n",
    "\n",
    "Actor_loss = T.mean(Actor_loss)\n",
    "self.actor.train()\n",
    "self.actor.optimizer.zero_grad()\n",
    "Actor_loss.backward()\n",
    "self.actor.optimizer.step()\n",
    "\n",
    "self.update_network_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trajectory, test_trajectory_return= test_agent.sample_trajectory(10.0)\n",
    "test_agent.plot_trajectory(test_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDPGAlgorithm(point_charge_in_electric_field, test_agent, 800, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, path_return= test_agent.sample_trajectory(10.0)\n",
    "test_agent.plot_trajectory(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
